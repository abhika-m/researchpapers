# Research Papers 
A collection of summaries of recent research papers + articles I have read and my understanding of them. These papers are mostly in the domain of Natural Language Processing. Click on the links for a short summary!

|Research Paper|Short Description|
|-|-|
|[NaturalProver](https://github.com/abhika-m/researchpapers/blob/main/NaturalProver.md)|An NLP model which improves mathematical proof generation as well next step generation for proofs 
|[CORA](https://github.com/abhika-m/researchpapers/blob/main/CORA.md)|Focuses on improving QA models to utilize documents from multiple languages when generating answers in order to increase inclusivety and make otherwise unanswerable questions due to lack of data answerable
|[Commonsense Generation](https://github.com/abhika-m/researchpapers/blob/main/CommonSenseReasoning.md)| Looks at using generated knowledge statements to improve accuracy of QA models
|[Delphi Experiment](https://github.com/abhika-m/researchpapers/blob/main/DelphiExperiment.md)|An NLP model which determines whether a statement or question is ethical or not, [try demo here](https://delphi.allenai.org/)
|[Red Teaming](https://github.com/abhika-m/researchpapers/blob/main/RedTeaming.md)|Looking at incorporating red teaming efforts (purposefully producing harmful results to update models to prevent that from happening again) to reduce harmful and offensive responses by AI assistants
|[PURR](https://github.com/abhika-m/researchpapers/blob/main/PURR.md)|Explores editing hallucinations in large language model outputs through using a synthetic corrupted dataset
|[LoRA](https://github.com/abhika-m/researchpapers/blob/main/LoRA.md)|Describes a method to make fine tuning more efficient by using lower ranks to update model weights rather than updating all parameters in models, especially useful when finetuning large models
|[RARR](https://github.com/abhika-m/researchpapers/blob/main/RARR.md)|Focuses on improving trushtworthiness of large language models through the process of revision
|[Unlearning](https://github.com/abhika-m/researchpapers/blob/main/UnlearningInLLMs)|Looks at unlearning targetted information within large language models and their outputs.
